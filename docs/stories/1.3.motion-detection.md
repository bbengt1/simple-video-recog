# Story 1.3: Motion Detection Implementation

## Status
Draft

## Story
**As a** developer,
**I want** to detect motion in video frames using OpenCV background subtraction,
**so that** I can filter out static scenes and only process frames with activity.

## Acceptance Criteria

1. Motion detection module (core/motion.py) implements MotionDetector class with detect_motion(frame) method
2. Uses OpenCV BackgroundSubtractorMOG2 algorithm for motion detection (handles lighting changes, shadows)
3. motion_threshold parameter from configuration controls sensitivity (0-255, lower = more sensitive)
4. detect_motion() returns tuple: (has_motion: bool, confidence: float, motion_mask: numpy array)
5. has_motion is True when percentage of changed pixels exceeds threshold (default: 2% of frame)
6. confidence score represents percentage of frame with detected motion (0.0 to 1.0)
7. motion_mask is binary image showing areas of detected motion (useful for debugging/visualization)
8. Background model learns over first 100 frames to establish baseline (ignores motion during learning phase)
9. Motion detector resets background model on manual trigger (via future API) or after major scene change
10. Performance: Motion detection completes in <50ms per frame on M1 (measured via unit test with time.perf_counter)
11. Unit tests verify: motion detected in test videos with known movement, static scenes return has_motion=False, threshold configuration works correctly
12. Edge cases tested: sudden lighting change, gradual lighting change (sunrise/sunset), shadow movement

## Tasks / Subtasks

- [ ] **Task 1: Create MotionDetector class structure** (AC: 1)
  - [ ] Create `core/motion_detector.py` module file (Note: Architecture says motion_detector.py, AC says motion.py)
  - [ ] Define `MotionDetector` class with constructor accepting `SystemConfig`
  - [ ] Add `__init__` method with dependency injection for config
  - [ ] Initialize BackgroundSubtractorMOG2 instance with history=500, varThreshold=16
  - [ ] Store motion_threshold from config as instance variable
  - [ ] Add frame counter for 100-frame learning phase
  - [ ] Add proper type hints and Google-style class docstring

- [ ] **Task 2: Implement detect_motion() method** (AC: 2, 4, 5, 6, 7)
  - [ ] Implement `detect_motion(frame: np.ndarray) -> tuple[bool, float, np.ndarray]` method
  - [ ] Apply BackgroundSubtractorMOG2 to generate foreground mask
  - [ ] Calculate confidence as percentage of changed pixels (count non-zero pixels in mask)
  - [ ] Determine has_motion by comparing confidence to threshold (default: 2% = 0.02)
  - [ ] Return tuple: (has_motion, confidence, motion_mask)
  - [ ] During first 100 frames: build background model, return (False, 0.0, empty_mask)
  - [ ] Add docstring with Args, Returns sections

- [ ] **Task 3: Implement reset_background() method** (AC: 9)
  - [ ] Implement `reset_background() -> None` method
  - [ ] Create new BackgroundSubtractorMOG2 instance (resets learned background)
  - [ ] Reset frame counter to 0 (restart learning phase)
  - [ ] Log INFO message "Background model reset"
  - [ ] Add Google-style docstring

- [ ] **Task 4: Add configuration parameter mapping** (AC: 3)
  - [ ] Extract motion_threshold from SystemConfig (0.0-1.0 range, not 0-255)
  - [ ] Note: AC says 0-255 but SystemConfig uses 0.0-1.0, use SystemConfig spec
  - [ ] Validate threshold is in range [0.0, 1.0] (Pydantic already validates)
  - [ ] Default threshold: 0.02 (2% of frame) as stated in AC 5

- [ ] **Task 5: Implement performance optimization** (AC: 10)
  - [ ] Ensure MOG2 parameters optimized: history=500, varThreshold=16
  - [ ] Use efficient numpy operations for confidence calculation
  - [ ] Avoid unnecessary array copies
  - [ ] Measure performance in unit test: wrap detect_motion() with time.perf_counter()
  - [ ] Assert processing time <50ms per frame

- [ ] **Task 6: Add unit tests for MotionDetector** (AC: 11)
  - [ ] Create `tests/unit/test_motion_detector.py` file
  - [ ] Test 1: `test_detect_motion_static_scene()` - verify no motion on static frames
  - [ ] Test 2: `test_detect_motion_with_movement()` - verify motion detected when frame changes
  - [ ] Test 3: `test_learning_phase()` - verify first 100 frames return has_motion=False
  - [ ] Test 4: `test_confidence_calculation()` - verify confidence is percentage (0.0-1.0)
  - [ ] Test 5: `test_motion_threshold_configuration()` - verify threshold parameter works
  - [ ] Test 6: `test_reset_background()` - verify background reset restarts learning phase
  - [ ] Test 7: `test_performance_requirement()` - verify <50ms per frame using time.perf_counter()
  - [ ] Use mock frames (numpy arrays) created with pytest fixtures
  - [ ] Achieve ≥80% coverage for core/ module (per architecture requirement)

- [ ] **Task 7: Add edge case tests** (AC: 12)
  - [ ] Test 8: `test_sudden_lighting_change()` - verify MOG2 handles sudden brightness change
  - [ ] Test 9: `test_gradual_lighting_change()` - verify adaptation to slow lighting drift
  - [ ] Test 10: `test_shadow_movement()` - verify MOG2 detectShadows parameter filters shadows
  - [ ] Create synthetic test frames simulating each edge case
  - [ ] Document expected behavior for each edge case in test docstrings

## Dev Notes

### Previous Story Insights

From Story 1.2 (RTSP Camera Connection):
- Project uses Python 3.10+ with `|` union type syntax for type hints
- Pydantic v2 ConfigDict pattern used (no deprecation warnings)
- SystemConfig model exists in `core/config.py` with `motion_threshold` field (0.0-1.0 range)
- Test coverage target for core/: ≥80% (per architecture requirement)
- pytest configured in pyproject.toml with coverage reporting
- Google-style docstrings required for all public methods
- Line length: 100 characters maximum
- [Source: docs/stories/1.2.rtsp-camera-connection.md#Dev Agent Record]

### Motion Detector Specification

**Module Path:** `core/motion_detector.py`

**IMPORTANT FILE NAMING CONFLICT:**
- AC 1 specifies: `core/motion.py`
- Architecture specifies: `core/motion_detector.py`
- **RESOLUTION:** Use `core/motion_detector.py` (follows architecture naming conventions)
- Class name: `MotionDetector` (both sources agree)

**Key Interfaces:**
- `detect_motion(frame: np.ndarray) -> tuple[bool, float, np.ndarray]`: Returns (has_motion, confidence_score, motion_mask)
- `reset_background() -> None`: Reset background model (called when camera moves)

**Dependencies:**
- OpenCV (cv2.createBackgroundSubtractorMOG2)
- SystemConfig (for motion_threshold parameter)

**Technology Stack:**
- Python 3.10+, OpenCV 4.8.1+ (MOG2 background subtraction)

**Implementation Notes:**
- Uses MOG2 algorithm with history=500 frames, varThreshold=16
- Confidence calculated as percentage of changed pixels above threshold
- Motion detected if confidence >= motion_threshold from config
- First 100 frames used to build initial background model (no motion detection during learning)

[Source: docs/architecture/motion-detector.md]

### Motion Threshold Configuration

**IMPORTANT THRESHOLD RANGE CONFLICT:**
- AC 3 states: "motion_threshold parameter from configuration controls sensitivity (0-255, lower = more sensitive)"
- SystemConfig specification: `motion_threshold: float = Field(default=0.5, ge=0.0, le=1.0, description="Motion detection sensitivity")`
- **RESOLUTION:** Use SystemConfig spec (0.0-1.0 range), AC 3 is incorrect
- Default: 0.02 (2% of frame) as stated in AC 5
- Range: 0.0 to 1.0 (0.0 = very sensitive, 1.0 = less sensitive)

**SystemConfig.motion_threshold field:**
```python
motion_threshold: float = Field(
    default=0.5,
    ge=0.0,
    le=1.0,
    description="Motion detection sensitivity (0=very sensitive, 1=less sensitive)"
)
```

[Source: docs/architecture/systemconfig.md, core/config.py:29-34]

### OpenCV BackgroundSubtractorMOG2 Parameters

**MOG2 Algorithm Configuration:**
```python
bg_subtractor = cv2.createBackgroundSubtractorMOG2(
    history=500,          # Number of last frames that affect background model
    varThreshold=16,      # Threshold on squared Mahalanobis distance
    detectShadows=True    # Detect and mark shadows (helps filter shadow movement)
)
```

**Why MOG2?**
- Handles lighting changes better than simple frame differencing
- Adaptive background model adjusts to gradual changes (sunrise/sunset)
- detectShadows=True filters out shadow movement (addresses AC 12 edge case)
- Robust to camera noise and small movements

**Confidence Calculation:**
```python
# Apply background subtraction
fg_mask = bg_subtractor.apply(frame)

# Count non-zero pixels (detected motion pixels)
motion_pixels = np.count_nonzero(fg_mask)

# Calculate confidence as percentage of frame
total_pixels = fg_mask.shape[0] * fg_mask.shape[1]
confidence = motion_pixels / total_pixels  # Range: 0.0 to 1.0

# Determine if motion threshold exceeded
has_motion = confidence >= motion_threshold  # Default: 0.02 (2% of frame)
```

[Source: OpenCV documentation, docs/architecture/motion-detector.md]

### Repository Structure

**Module Location:** `core/motion_detector.py`

The `core/` directory contains platform-independent business logic. Motion detection is a core algorithmic component, independent of platform or external services.

**Directory Structure:**
```
video-recognition/
├── core/              # Platform-independent business logic
│   ├── config.py      # SystemConfig model (Story 1.1)
│   ├── exceptions.py  # Custom exception hierarchy (Story 1.2)
│   └── motion_detector.py  # ← THIS STORY
├── integrations/      # External service clients (RTSP from Story 1.2)
├── platform/          # Apple Silicon-specific implementations (future)
└── tests/             # Test organization mirrors source structure
    └── unit/
        ├── test_config.py         # Story 1.1
        ├── test_rtsp_client.py    # Story 1.2
        └── test_motion_detector.py  # ← THIS STORY
```

[Source: docs/architecture/repository-structure.md]

### Performance Requirements

**Target: <50ms per frame on M1 MacBook Pro**

**Optimization strategies:**
- Use efficient numpy operations for pixel counting (np.count_nonzero)
- Avoid unnecessary array copies (operate on views where possible)
- MOG2 is implemented in C++ (cv2 binding), very fast
- Measure performance in unit test using time.perf_counter()

**Performance Testing:**
```python
import time

def test_performance_requirement(motion_detector, mock_frame):
    """Verify motion detection completes in <50ms per frame."""
    # Build background model first (100 frames)
    for _ in range(100):
        motion_detector.detect_motion(mock_frame)

    # Measure performance on 101st frame
    start_time = time.perf_counter()
    has_motion, confidence, mask = motion_detector.detect_motion(mock_frame)
    end_time = time.perf_counter()

    processing_time_ms = (end_time - start_time) * 1000
    assert processing_time_ms < 50, f"Processing took {processing_time_ms:.2f}ms, exceeds 50ms limit"
```

**Expected performance:**
- MOG2 apply(): ~5-15ms per frame
- Confidence calculation: ~1-3ms
- Total: ~10-20ms typical (well under 50ms limit)

[Source: docs/architecture/performance-optimization.md]

### Python Code Style

**Line Length:** Maximum 100 characters

**Type Hints:** Use Python 3.10+ union syntax
```python
def detect_motion(self, frame: np.ndarray) -> tuple[bool, float, np.ndarray]:
```

**Imports Order:**
```python
# Standard library imports
import time
from typing import Optional

# Third-party imports
import cv2
import numpy as np

# Local application imports
from core.config import SystemConfig
```

**String Quotes:** Prefer double quotes `"`

**F-strings:** Use for formatting
```python
logger.info(f"Background model reset for camera: {camera_id}")
```

**Docstrings:** Google style with Args, Returns sections
```python
def detect_motion(self, frame: np.ndarray) -> tuple[bool, float, np.ndarray]:
    """Detect motion in video frame using background subtraction.

    During the first 100 frames, the background model is being learned,
    so this method will always return (False, 0.0, empty_mask).

    Args:
        frame: OpenCV frame in BGR format (numpy array)

    Returns:
        Tuple of:
        - has_motion (bool): True if motion exceeds threshold
        - confidence (float): Percentage of frame with motion (0.0-1.0)
        - motion_mask (np.ndarray): Binary mask of detected motion
    """
```

[Source: docs/architecture/python-code-style.md]

### Critical Fullstack Rules (Relevant to This Story)

1. **Type Safety:** Use Pydantic models for configuration. SystemConfig already has motion_threshold field.

2. **Dependency Injection:** MotionDetector must receive SystemConfig through constructor, never instantiate internally.

3. **Error Handling:** All exceptions caught at module boundaries, logged with context. Never silently swallow exceptions.

4. **Logging Standards:** Use structured logging:
   ```python
   logger.info(f"Motion detected: {confidence:.2%}", extra={"confidence": confidence})
   ```

5. **Import Organization:** Follow PEP 8 order: standard library, third-party, local application.

[Source: docs/architecture/critical-fullstack-rules.md]

### Error Handling

**Custom Exception Hierarchy:**

The custom exception hierarchy already exists from Story 1.2:

```python
# core/exceptions.py (created in Story 1.2)
class VideoRecognitionError(Exception):
    """Base exception for all application errors."""
    pass

class RTSPConnectionError(VideoRecognitionError):
    """RTSP camera connection failed."""
    pass
```

No new exceptions needed for motion detection. Frame processing errors should be handled gracefully (log warning, continue processing).

[Source: docs/architecture/error-handling-standards.md, docs/stories/1.2.rtsp-camera-connection.md]

### File Naming Conventions

- Python modules: snake_case → `motion_detector.py`
- Python classes: PascalCase → `MotionDetector`
- Test files: `test_*.py` → `test_motion_detector.py`

[Source: docs/architecture/file-naming-conventions.md]

## Testing

### Test Organization

**Test File:** `tests/unit/test_motion_detector.py`

Tests mirror source structure: `core/motion_detector.py` → `tests/unit/test_motion_detector.py`

[Source: docs/architecture/test-organization.md]

### Coverage Requirements

**Target for core/ module:** ≥80% code coverage

This is higher than integrations/ (≥60%) because core/ contains critical business logic.

**Coverage Command:**
```bash
pytest tests/unit/test_motion_detector.py --cov=core.motion_detector --cov-report=term
```

[Source: docs/architecture/test-coverage-requirements.md]

### Unit Test Best Practices

1. **Use pytest fixtures:** Create `mock_frame` fixture in conftest.py (already exists from Story 1.2)
2. **Test edge cases:** Lighting changes, shadow movement, threshold boundaries
3. **Test error conditions:** Invalid frame shapes, None inputs
4. **Parametrize tests:** Test multiple threshold values in single test

**Example Fixture Usage:**
```python
# tests/conftest.py (already exists from Story 1.2)
@pytest.fixture
def mock_frame():
    """Create mock OpenCV frame (numpy array)."""
    import numpy as np
    return np.zeros((480, 640, 3), dtype=np.uint8)

@pytest.fixture
def sample_config():
    """Create sample SystemConfig for testing."""
    from core.config import SystemConfig
    return SystemConfig(
        camera_rtsp_url="rtsp://test:test@192.168.1.100:554/stream1",
        camera_id="test_camera",
        motion_threshold=0.02  # 2% of frame (default per AC 5)
    )
```

**Example Parametrized Test:**
```python
import pytest

@pytest.mark.parametrize("threshold,expected_motion", [
    (0.01, True),   # Low threshold (1%), should detect motion
    (0.05, False),  # High threshold (5%), might not detect motion
])
def test_motion_detection_thresholds(threshold, expected_motion, mock_frame):
    """Test motion detection with different threshold values."""
    from core.config import SystemConfig
    from core.motion_detector import MotionDetector

    config = SystemConfig(
        camera_rtsp_url="rtsp://test:test@192.168.1.100:554/stream1",
        motion_threshold=threshold
    )
    detector = MotionDetector(config)

    # Build background model (100 frames)
    for _ in range(100):
        detector.detect_motion(mock_frame)

    # Create frame with motion (white square in center)
    changed_frame = mock_frame.copy()
    changed_frame[200:280, 300:380] = 255  # 80x80 white square

    has_motion, confidence, mask = detector.detect_motion(changed_frame)

    assert isinstance(has_motion, bool)
    assert isinstance(confidence, float)
    assert 0.0 <= confidence <= 1.0
    assert isinstance(mask, np.ndarray)
```

[Source: docs/architecture/unit-test-best-practices.md]

### Edge Case Testing (AC 12)

**Sudden Lighting Change:**
```python
def test_sudden_lighting_change(motion_detector, mock_frame):
    """Test MOG2 handles sudden brightness change without false positive."""
    # Build background model with normal brightness
    for _ in range(100):
        motion_detector.detect_motion(mock_frame)

    # Simulate sudden brightness increase (e.g., lights turned on)
    bright_frame = mock_frame.copy()
    bright_frame = np.clip(bright_frame.astype(np.int16) + 50, 0, 255).astype(np.uint8)

    has_motion, confidence, mask = motion_detector.detect_motion(bright_frame)

    # MOG2 should detect this as a global change, not motion
    # After a few frames, background model should adapt
    # Test that motion detector doesn't permanently flag this as motion
```

**Gradual Lighting Change (Sunrise/Sunset):**
```python
def test_gradual_lighting_change(motion_detector, mock_frame):
    """Test MOG2 adapts to gradual lighting changes."""
    # Simulate sunrise: gradually increase brightness over 200 frames
    for i in range(200):
        brightness_delta = int(i * 0.5)  # Slow gradual increase
        adjusted_frame = np.clip(
            mock_frame.astype(np.int16) + brightness_delta, 0, 255
        ).astype(np.uint8)

        has_motion, confidence, mask = motion_detector.detect_motion(adjusted_frame)

        # After learning phase, gradual changes should NOT trigger motion
        if i >= 100:
            assert confidence < 0.05, f"Frame {i}: False positive on gradual lighting change"
```

**Shadow Movement:**
```python
def test_shadow_movement(motion_detector, mock_frame):
    """Test MOG2 detectShadows parameter filters shadow movement."""
    # Build background model
    for _ in range(100):
        motion_detector.detect_motion(mock_frame)

    # Create frame with shadow (darker region, not complete darkness)
    shadow_frame = mock_frame.copy()
    shadow_frame[100:200, 100:200] = shadow_frame[100:200, 100:200] // 2  # 50% darker

    has_motion, confidence, mask = motion_detector.detect_motion(shadow_frame)

    # With detectShadows=True, shadows are marked but not counted as motion
    # Confidence should be low (shadow filtered out)
    assert confidence < 0.02, "Shadow movement incorrectly detected as motion"
```

[Source: docs/architecture/unit-test-best-practices.md]

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-09 | 1.0 | Initial story creation with comprehensive dev notes | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be filled by Dev Agent_

### Debug Log References
_To be filled by Dev Agent_

### Completion Notes
_To be filled by Dev Agent_

### File List

**Created:**
_To be filled by Dev Agent_

**Modified:**
_To be filled by Dev Agent_

## QA Results
_To be filled by QA Agent_
