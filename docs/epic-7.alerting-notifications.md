# Epic 7: Alerting & Notifications

**Status:** üìã Proposed
**Priority:** High
**Dependencies:** Epic 5 (Web Dashboard), Epic 6 (Advanced Analytics - anomaly detection)
**Estimated Effort:** 70-90 hours (9-11 days)
**Target Release:** Phase 3

---

## Executive Summary

Epic 7 transforms the video recognition system from a passive monitoring tool into a proactive alert system. Building on Epic 5's dashboard and Epic 6's anomaly detection, this epic adds configurable notifications via multiple channels (email, SMS, Slack, Discord, webhooks) to ensure critical events are never missed.

**Key Deliverables:**
- Multi-channel notification delivery (email, SMS, Slack, Discord, webhooks)
- Custom alert rule engine (conditions, thresholds, schedules)
- Alert management dashboard (acknowledge, snooze, dismiss)
- Alert history and audit log
- Escalation policies (if not acknowledged within X minutes)
- Notification templates and customization
- Rate limiting and deduplication

---

## Business Value

### Problem Statement

After deploying the dashboard (Epic 5) and analytics (Epic 6), operators can:
- ‚úÖ Monitor events in real-time on the dashboard
- ‚úÖ View analytics and detect anomalies
- ‚úÖ Generate reports

However, they **cannot:**
- ‚ùå Receive notifications when critical events occur (e.g., motion detected at 2 AM)
- ‚ùå Get alerts on their mobile devices when away from the dashboard
- ‚ùå Configure custom alert rules ("notify me if person detected in Zone A after hours")
- ‚ùå Integrate with existing communication tools (Slack, email)
- ‚ùå Escalate unacknowledged alerts to supervisors
- ‚ùå Track alert response times and acknowledgements

### Value Proposition

**For Security Operators:**
- Receive instant notifications on mobile devices (SMS, push)
- Configure personalized alert preferences
- Acknowledge and manage alerts from mobile

**For Security Teams:**
- Integrate with team chat (Slack, Discord, Microsoft Teams)
- Shared alert visibility and collaboration
- Alert escalation to ensure no incident is missed

**For Security Managers:**
- Track alert response times and SLAs
- Audit trail of all alerts and acknowledgements
- Data-driven alerting to reduce false positives

### Success Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| Alert delivery latency | <10 seconds | Time from event to notification received |
| Notification success rate | >99% | Delivered / total alerts |
| False positive rate | <10% | False alerts / total alerts |
| Average acknowledgement time | <5 minutes | Time to acknowledge critical alerts |
| Alert-driven incident detection | >80% | Incidents discovered via alerts vs manual monitoring |

---

## User Stories

### Epic-Level User Stories

**Story 1: Email Notifications**
> As a security operator, I want to receive email notifications for critical events (e.g., motion detected after hours), so that I can respond quickly even when away from my desk.

**Story 2: SMS Notifications**
> As a security manager, I want to receive SMS text messages for high-severity alerts (e.g., anomaly detected), so that I'm notified immediately on my mobile device.

**Story 3: Slack Integration**
> As a security team, we want motion detection alerts posted to our Slack channel, so that the entire team has shared visibility and can collaborate on incidents.

**Story 4: Custom Alert Rules**
> As a security operator, I want to create custom alert rules (e.g., "notify me if person detected in Zone A between 10 PM and 6 AM"), so that I only receive relevant notifications.

**Story 5: Alert Management Dashboard**
> As a security operator, I want to acknowledge, snooze, or dismiss alerts from the dashboard, so that I can track which alerts I've reviewed and prioritize my response.

**Story 6: Alert History and Audit Log**
> As a security manager, I want to view a complete history of all alerts with acknowledgement timestamps and user actions, so that I can audit response times and compliance.

**Story 7: Escalation Policies**
> As a security manager, I want unacknowledged critical alerts to escalate to my supervisor after 10 minutes, so that no critical incident is missed.

**Story 8: Webhook Integration**
> As a system administrator, I want to send alerts to custom webhook URLs (e.g., PagerDuty, Opsgenie), so that we can integrate with our existing incident management tools.

---

## Technical Requirements

### Functional Requirements

**FR1: Email Notifications**
- Send email alerts via SMTP (configurable mail server)
- HTML email templates with event details and thumbnail image
- Email recipients: Single user, group, or distribution list
- Subject line format: "[ALERT] Motion detected at Camera 1 - 2025-11-10 14:30"
- Clickable link to event in dashboard
- Unsubscribe link for non-critical alerts

**FR2: SMS Notifications**
- Send SMS via Twilio, AWS SNS, or similar provider
- SMS format: "ALERT: Motion detected at Camera 1. View: http://dash.example.com/events/123"
- Character limit handling (160 chars)
- Rate limiting to prevent SMS spam
- Opt-in verification (users must confirm phone number)

**FR3: Slack Integration**
- Post alerts to Slack channel via webhook
- Rich message formatting (attachments with event details)
- Thumbnail image inline
- Action buttons: "Acknowledge", "View Event", "Snooze 15min"
- Slack app or incoming webhook (both supported)

**FR4: Discord Integration**
- Post alerts to Discord channel via webhook
- Embed message with event details and thumbnail
- Color-coded severity (red = critical, yellow = warning, blue = info)
- Clickable link to dashboard event

**FR5: Custom Alert Rules**
- Rule builder UI (condition + action)
- Conditions: Camera, time range, object type, confidence threshold, anomaly detection
- Actions: Notify via email/SMS/Slack/Discord/webhook
- Rule priority (1-5, higher priority = more urgent)
- Enable/disable rules
- Rule testing ("test this rule now")

**FR6: Alert Management Dashboard**
- List view: All alerts (newest first)
- Filter by: Status (pending, acknowledged, snoozed, dismissed), severity, date range
- Actions: Acknowledge (with note), snooze (15min, 1h, 4h, custom), dismiss
- Bulk actions: Acknowledge multiple alerts
- Alert detail view: Event info, rule triggered, notification history

**FR7: Alert History and Audit Log**
- Complete history of all alerts (no deletion)
- Audit fields: Created, acknowledged, acknowledged_by, acknowledged_at, notes
- Retention policy: Keep all alerts for 90 days, archive older
- Export history as CSV
- Statistics: Total alerts, avg acknowledgement time, response rate

**FR8: Escalation Policies**
- Define escalation chain (e.g., Operator ‚Üí Supervisor ‚Üí Manager)
- Time thresholds (e.g., escalate after 10 minutes if not acknowledged)
- Escalation actions: Send additional notification, increase severity
- Escalation log (who was notified at each level)
- Override escalation (manual escalation or de-escalation)

**FR9: Webhook Integration**
- Generic webhook support (POST JSON payload)
- Configurable webhook URL, headers, authentication
- Payload customization (event details, timestamp, severity)
- Retry logic (3 attempts with exponential backoff)
- Webhook delivery confirmation

**FR10: Rate Limiting and Deduplication**
- Rate limiting: Max X alerts per hour per rule
- Deduplication: Don't send duplicate alerts within Y minutes
- Grouping: Combine multiple similar alerts into one digest
- Quiet hours: Suppress non-critical alerts during specified times

---

### Non-Functional Requirements

**NFR53: Alert Delivery Latency**
- Alert delivery: <10 seconds from event occurrence
- Email delivery: <30 seconds
- SMS delivery: <15 seconds
- Slack/Discord delivery: <5 seconds

**NFR54: Notification Success Rate**
- Email: >99% delivery rate
- SMS: >98% delivery rate
- Slack/Discord: >99.9% delivery rate
- Webhook: >95% success rate (with retries)

**NFR55: System Reliability**
- Alert system uptime: >99.9% (8.76 hours downtime per year)
- Queue-based delivery (no lost alerts on system restart)
- Graceful degradation (continue processing if one channel fails)

**NFR56: Security**
- Encrypt sensitive data (phone numbers, API keys, webhook URLs)
- API key storage: Environment variables or encrypted config
- Authentication for webhook endpoints (API key, OAuth)
- Rate limiting to prevent abuse

**NFR57: Scalability**
- Support 10,000+ alerts per day
- Handle 100+ concurrent notification deliveries
- Queue processing: <1000 alerts per minute

**NFR58: Privacy Compliance**
- GDPR compliance: User consent for notifications
- Opt-out mechanism for non-critical alerts
- Data retention policy (90 days)
- Right to erasure (delete notification history on request)

---

## Story Breakdown

### Story 7.1: Email Notification System (8-10 hours)

**Description:** Send email alerts for critical events with HTML templates and event details.

**Acceptance Criteria:**
- Configure SMTP server (host, port, username, password)
- HTML email template with event details and thumbnail
- Send email on alert trigger
- Email delivery confirmation (SMTP success/failure)
- Clickable link to event in dashboard
- Handle email delivery failures (log and retry)

**Technical Approach:**
- Python `smtplib` or `aiosmtplib` for async email sending
- Jinja2 templates for HTML emails
- Queue-based delivery (Celery or built-in asyncio queue)
- Configuration: `config/config.yaml` - email settings

**Estimated Effort:** 8-10 hours

---

### Story 7.2: SMS Notification System (8-10 hours)

**Description:** Send SMS text messages via Twilio or AWS SNS for high-severity alerts.

**Acceptance Criteria:**
- Integrate with Twilio API (or AWS SNS)
- Send SMS on alert trigger
- Format SMS message (160 char limit)
- Phone number validation and opt-in verification
- SMS delivery confirmation
- Rate limiting (max 10 SMS per hour per user)

**Technical Approach:**
- Twilio Python SDK: `twilio` library
- Phone number validation: `phonenumbers` library
- Opt-in verification: Two-factor auth code
- Configuration: `config/config.yaml` - Twilio account SID, auth token

**Estimated Effort:** 8-10 hours

---

### Story 7.3: Slack Integration (8-10 hours)

**Description:** Post alerts to Slack channel with rich formatting and action buttons.

**Acceptance Criteria:**
- Configure Slack webhook URL
- Send alert to Slack channel
- Rich message formatting (attachments, colors)
- Thumbnail image inline
- Action buttons: "Acknowledge", "View Event"
- Handle Slack API rate limits

**Technical Approach:**
- Slack Incoming Webhook or Slack API
- Python `slack_sdk` library
- Message formatting: Slack Block Kit
- Configuration: `config/config.yaml` - Slack webhook URL

**Estimated Effort:** 8-10 hours

---

### Story 7.4: Custom Alert Rules Engine (12-14 hours)

**Description:** Rule builder UI and backend engine to create custom alert conditions.

**Acceptance Criteria:**
- Rule builder UI (web interface)
- Conditions: Camera, time range, object type, confidence, anomaly
- Actions: Notify via email/SMS/Slack/Discord
- Rule priority (1-5)
- Enable/disable rules
- Test rule ("test this rule now")
- Rule evaluation engine (real-time and scheduled)

**Technical Approach:**
- Rule storage: SQLite table `alert_rules`
- Rule evaluation: Python functions for each condition type
- Real-time evaluation: On event creation (event hook)
- Scheduled evaluation: Background job for time-based rules
- UI: JavaScript form builder

**Estimated Effort:** 12-14 hours

---

### Story 7.5: Alert Management Dashboard (10-12 hours)

**Description:** Dashboard to view, acknowledge, snooze, and dismiss alerts.

**Acceptance Criteria:**
- List view: All alerts (newest first)
- Filter by status, severity, date range
- Actions: Acknowledge (with note), snooze, dismiss
- Bulk actions: Acknowledge multiple alerts
- Alert detail view: Event info, rule triggered, history
- Real-time updates (WebSocket)

**Technical Approach:**
- Frontend: JavaScript component (similar to EventFeed)
- Backend: `GET /api/alerts` endpoint
- WebSocket: Real-time alert updates
- Database: `alerts` table with status tracking

**Estimated Effort:** 10-12 hours

---

### Story 7.6: Alert History and Audit Log (8-10 hours)

**Description:** Complete history of all alerts with acknowledgement tracking and audit log.

**Acceptance Criteria:**
- View all alerts (no deletion)
- Audit fields: Created, acknowledged_by, acknowledged_at, notes
- Filter by date range, user, status
- Export history as CSV
- Statistics: Total alerts, avg acknowledgement time

**Technical Approach:**
- Database: `alerts` table with full audit trail
- Endpoint: `GET /api/alerts/history`
- CSV export: Pandas `to_csv()`
- Statistics calculation: SQL aggregations

**Estimated Effort:** 8-10 hours

---

### Story 7.7: Escalation Policies (10-12 hours)

**Description:** Escalate unacknowledged critical alerts to supervisors after timeout.

**Acceptance Criteria:**
- Define escalation chain (Operator ‚Üí Supervisor ‚Üí Manager)
- Time thresholds (e.g., 10 minutes)
- Escalation actions: Send additional notification
- Escalation log (who was notified at each level)
- Manual escalation override

**Technical Approach:**
- Database: `escalation_policies` table
- Background job: Check unacknowledged alerts every minute
- Escalation logic: Time-based triggers
- Notification: Reuse email/SMS/Slack from Stories 7.1-7.3

**Estimated Effort:** 10-12 hours

---

### Story 7.8: Webhook Integration (8-10 hours)

**Description:** Send alerts to custom webhook URLs for integration with external tools.

**Acceptance Criteria:**
- Configure webhook URL, headers, authentication
- POST JSON payload on alert trigger
- Retry logic (3 attempts, exponential backoff)
- Webhook delivery confirmation
- Support popular services (PagerDuty, Opsgenie, Zapier)

**Technical Approach:**
- Python `requests` library for HTTP POST
- Retry decorator: `tenacity` library
- Payload format: Standardized JSON schema
- Configuration: `config/config.yaml` - webhook URLs

**Estimated Effort:** 8-10 hours

---

## Technical Architecture

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             Alerting & Notification System              ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Event Detection (Triggers)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - New motion detection event                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Anomaly detected (from Epic 6)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Manual alert creation                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                 ‚îÇ                                       ‚îÇ
‚îÇ                 ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Alert Rule Engine                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Evaluate custom alert rules                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Check conditions (camera, time, object, etc)‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Determine severity (critical, warning, info) ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Select notification channels                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                 ‚îÇ                                       ‚îÇ
‚îÇ                 ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Alert Queue (Async Processing)                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - asyncio.Queue or Celery                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Priority queue (critical alerts first)       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Deduplication (prevent duplicate alerts)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Rate limiting (max X per hour)               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                 ‚îÇ                                       ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ         ‚ñº                  ‚ñº          ‚ñº          ‚ñº    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  Email   ‚îÇ  ‚îÇ  SMS (Twilio)‚îÇ  ‚îÇ  Slack  ‚îÇ  ‚îÇWebH‚îÇ‚îÇ
‚îÇ  ‚îÇ  (SMTP)  ‚îÇ  ‚îÇ  (AWS SNS)   ‚îÇ  ‚îÇ Discord ‚îÇ  ‚îÇook ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ         ‚îÇ                  ‚îÇ          ‚îÇ          ‚îÇ    ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                 ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Delivery Confirmation & Retry                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Track delivery status (sent, failed, retry) ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Retry failed deliveries (3 attempts)        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Log all delivery attempts                   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                 ‚îÇ                                       ‚îÇ
‚îÇ                 ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Alert Management Database                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - alerts table (all alerts + audit trail)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - alert_rules table (custom rules)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - escalation_policies table                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - notification_log table (delivery history)   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Background Jobs (Scheduler)                ‚îÇ
‚îÇ  - Escalation Policy Checker (runs every minute)       ‚îÇ
‚îÇ  - Alert Cleanup Job (archive alerts >90 days)         ‚îÇ
‚îÇ  - Notification Retry Job (retry failed deliveries)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Frontend Components                     ‚îÇ
‚îÇ  - Alert Management Dashboard (view, ack, snooze)      ‚îÇ
‚îÇ  - Alert Rule Builder (create custom rules)            ‚îÇ
‚îÇ  - Alert History Viewer (audit log)                    ‚îÇ
‚îÇ  - Escalation Policy Editor                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Technology Stack

**Backend:**
- **FastAPI:** Alert API endpoints
- **aiosmtplib:** Async email sending
- **Twilio Python SDK:** SMS notifications
- **slack_sdk:** Slack integration
- **requests:** Webhook HTTP POST
- **APScheduler:** Background jobs (escalation, cleanup)
- **asyncio:** Async queue processing
- **SQLAlchemy:** ORM for alert database

**Frontend:**
- **Vanilla JavaScript:** Alert dashboard components (consistent with Epic 5)
- **WebSocket:** Real-time alert updates

**External Services:**
- **SMTP Server:** Gmail, SendGrid, AWS SES, or self-hosted
- **Twilio:** SMS delivery
- **Slack:** Team chat integration
- **Discord:** Community chat integration

---

### Database Schema (New Tables)

```sql
-- Alert Rules (user-defined conditions)
CREATE TABLE alert_rules (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,                       -- e.g., "After-hours motion detection"
    description TEXT,
    enabled BOOLEAN DEFAULT 1,
    priority INTEGER DEFAULT 3,               -- 1 (lowest) to 5 (highest)
    conditions TEXT NOT NULL,                 -- JSON: { camera_id: "Camera 1", time_start: "22:00", ... }
    actions TEXT NOT NULL,                    -- JSON: { email: true, sms: false, slack: true, ... }
    created_by TEXT,                          -- User who created rule
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Alerts (triggered alerts with audit trail)
CREATE TABLE alerts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    alert_rule_id INTEGER,                    -- FK to alert_rules (null if manual)
    event_id TEXT,                            -- FK to events table (null if non-event alert)
    severity TEXT NOT NULL,                   -- 'critical', 'warning', 'info'
    title TEXT NOT NULL,                      -- e.g., "Motion detected in Zone A"
    message TEXT,                             -- Alert description
    status TEXT DEFAULT 'pending',            -- 'pending', 'acknowledged', 'snoozed', 'dismissed'
    acknowledged_by TEXT,                     -- User who acknowledged
    acknowledged_at TEXT,
    acknowledgement_note TEXT,
    snoozed_until TEXT,                       -- Timestamp for snooze expiration
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (alert_rule_id) REFERENCES alert_rules(id)
);

-- Notification Log (delivery history)
CREATE TABLE notification_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    alert_id INTEGER NOT NULL,
    channel TEXT NOT NULL,                    -- 'email', 'sms', 'slack', 'discord', 'webhook'
    recipient TEXT NOT NULL,                  -- Email, phone, webhook URL
    status TEXT NOT NULL,                     -- 'sent', 'failed', 'pending', 'retry'
    error_message TEXT,                       -- Error details if failed
    attempts INTEGER DEFAULT 1,               -- Retry count
    sent_at TEXT,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (alert_id) REFERENCES alerts(id)
);

-- Escalation Policies (alert escalation rules)
CREATE TABLE escalation_policies (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,                       -- e.g., "Critical Alert Escalation"
    alert_rule_id INTEGER,                    -- FK to alert_rules (null = applies to all)
    escalation_chain TEXT NOT NULL,           -- JSON: [{ level: 1, notify: "operator@example.com", timeout: 600 }, ...]
    enabled BOOLEAN DEFAULT 1,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (alert_rule_id) REFERENCES alert_rules(id)
);

-- Indexes for performance
CREATE INDEX idx_alerts_status ON alerts(status);
CREATE INDEX idx_alerts_created_at ON alerts(created_at DESC);
CREATE INDEX idx_alerts_severity ON alerts(severity);
CREATE INDEX idx_notification_log_alert_id ON notification_log(alert_id);
CREATE INDEX idx_notification_log_status ON notification_log(status);
```

---

### Configuration Schema

```yaml
# config/config.yaml - Alerting Configuration

alerting:
  enabled: true

  # Email Configuration (SMTP)
  email:
    enabled: true
    smtp_host: "smtp.gmail.com"
    smtp_port: 587
    smtp_username: "alerts@example.com"
    smtp_password: "${SMTP_PASSWORD}"  # Environment variable
    from_address: "alerts@example.com"
    from_name: "Video Recognition Alerts"

  # SMS Configuration (Twilio)
  sms:
    enabled: false
    provider: "twilio"  # or "aws_sns"
    twilio_account_sid: "${TWILIO_ACCOUNT_SID}"
    twilio_auth_token: "${TWILIO_AUTH_TOKEN}"
    twilio_from_number: "+15551234567"

  # Slack Configuration
  slack:
    enabled: false
    webhook_url: "${SLACK_WEBHOOK_URL}"
    channel: "#security-alerts"
    username: "Security Bot"
    icon_emoji: ":rotating_light:"

  # Discord Configuration
  discord:
    enabled: false
    webhook_url: "${DISCORD_WEBHOOK_URL}"
    username: "Security Bot"

  # Webhook Configuration (Generic)
  webhooks:
    - name: "PagerDuty"
      url: "${PAGERDUTY_WEBHOOK_URL}"
      headers:
        Authorization: "Token ${PAGERDUTY_API_KEY}"
      enabled: false

  # Rate Limiting
  rate_limits:
    max_alerts_per_hour: 100
    deduplication_window_minutes: 5

  # Quiet Hours (suppress non-critical alerts)
  quiet_hours:
    enabled: false
    start_time: "22:00"
    end_time: "07:00"
    suppress_severity: ["info", "warning"]  # Only allow "critical"
```

---

## Dependencies

### Epic 5 Dependencies

Epic 7 builds on Epic 5's foundation:
- ‚úÖ FastAPI web server (Story 5.1)
- ‚úÖ Event creation hooks (Story 5.5)
- ‚úÖ Dashboard UI structure (Story 5.4)

### Epic 6 Dependencies (Optional but Recommended)

- ‚úÖ Anomaly detection (Story 6.6) - Trigger alerts on anomalies
- ‚úÖ Predictive analytics (Story 6.7) - Predictive alerts ("high activity expected tomorrow")

### External Dependencies

**Python Libraries:**
- `aiosmtplib>=2.0.0` - Async email sending
- `twilio>=8.0.0` - SMS via Twilio
- `slack_sdk>=3.19.0` - Slack integration
- `requests>=2.31.0` - HTTP requests (webhooks)
- `phonenumbers>=8.13.0` - Phone number validation
- `jinja2>=3.1.0` - Email templates
- `apscheduler>=3.10.0` - Background jobs

**External Services:**
- SMTP server (Gmail, SendGrid, AWS SES)
- Twilio account (for SMS)
- Slack workspace (for Slack integration)
- Discord server (for Discord integration)

---

## Implementation Approach

### Phase 1: Core Notification Channels (Stories 7.1-7.3) - 3 days

**Goal:** Email, SMS, and Slack notifications

**Stories:**
- 7.1: Email Notification System
- 7.2: SMS Notification System
- 7.3: Slack Integration

**Deliverables:**
- Email sending via SMTP
- SMS sending via Twilio
- Slack webhook integration
- Notification delivery confirmation

---

### Phase 2: Alert Rules Engine (Story 7.4) - 2 days

**Goal:** Custom alert rule creation and evaluation

**Story:**
- 7.4: Custom Alert Rules Engine

**Deliverables:**
- Rule builder UI
- Rule evaluation engine
- Real-time rule triggers

---

### Phase 3: Alert Management (Stories 7.5-7.6) - 3 days

**Goal:** Alert dashboard and history

**Stories:**
- 7.5: Alert Management Dashboard
- 7.6: Alert History and Audit Log

**Deliverables:**
- Alert management UI
- Acknowledge/snooze/dismiss actions
- Complete audit trail

---

### Phase 4: Advanced Features (Stories 7.7-7.8) - 2 days

**Goal:** Escalation policies and webhook integration

**Stories:**
- 7.7: Escalation Policies
- 7.8: Webhook Integration

**Deliverables:**
- Escalation chain system
- Generic webhook support
- PagerDuty/Opsgenie integration

---

## Risks and Mitigations

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Email delivery failures (spam filters) | High | Medium | Use reputable SMTP provider (SendGrid, AWS SES), configure SPF/DKIM |
| SMS costs exceed budget | Medium | Medium | Implement rate limiting, allow users to opt-out, consider push notifications as alternative |
| Slack/Discord rate limits hit | Medium | Low | Implement exponential backoff, batch notifications, use official SDK |
| Alert fatigue (too many notifications) | High | High | Smart rate limiting, deduplication, user-configurable quiet hours |
| Escalation policy misconfiguration | High | Low | Validate escalation chain, test escalation policies, clear documentation |

---

## Success Criteria

Epic 7 is complete when:

- [ ] All 8 stories implemented and tested
- [ ] Email notifications delivered within 30 seconds
- [ ] SMS notifications delivered within 15 seconds
- [ ] Slack/Discord notifications delivered within 5 seconds
- [ ] Custom alert rules can be created via UI
- [ ] Alert management dashboard displays all alerts with real-time updates
- [ ] Alert history and audit log accessible with CSV export
- [ ] Escalation policies trigger correctly for unacknowledged alerts
- [ ] Webhook integration works with popular services (PagerDuty, Opsgenie)
- [ ] All NFRs met (delivery latency <10s, success rate >99%, uptime >99.9%)
- [ ] Rate limiting and deduplication prevent alert spam
- [ ] Privacy compliance (GDPR, opt-out mechanism)

---

## Future Enhancements (Post-Epic 7)

**Advanced Notification Channels:**
- Push notifications (mobile app via Firebase Cloud Messaging)
- Microsoft Teams integration
- Voice calls (Twilio voice API)
- In-app notifications (browser notifications API)

**Intelligent Alerting:**
- Machine learning-based alert prioritization
- Sentiment analysis of alert acknowledgement notes
- Automatic false positive detection and rule tuning
- Context-aware alerting (location, weather, calendar events)

**Mobile App Integration:**
- Dedicated mobile app for alert management
- Acknowledge/snooze alerts from mobile
- Push notifications to mobile devices
- GPS-based alert routing (notify closest operator)

**Advanced Escalation:**
- Round-robin escalation (distribute alerts evenly)
- On-call scheduling integration (PagerDuty, Opsgenie)
- Holiday and vacation calendar integration
- Multi-level escalation (L1 ‚Üí L2 ‚Üí L3 support)

---

## Estimated Timeline

| Story | Effort | Start | End |
|-------|--------|-------|-----|
| **7.1** Email Notification System | 8-10h | Day 1 | Day 2 |
| **7.2** SMS Notification System | 8-10h | Day 2 | Day 3 |
| **7.3** Slack Integration | 8-10h | Day 3 | Day 4 |
| **7.4** Custom Alert Rules Engine | 12-14h | Day 4 | Day 6 |
| **7.5** Alert Management Dashboard | 10-12h | Day 6 | Day 8 |
| **7.6** Alert History and Audit Log | 8-10h | Day 8 | Day 9 |
| **7.7** Escalation Policies | 10-12h | Day 9 | Day 10 |
| **7.8** Webhook Integration | 8-10h | Day 10 | Day 11 |

**Total Estimated Effort:** 72-90 hours (9-11 days)

---

## Budget Estimate

**Development Effort:** 72-90 hours
**Testing Effort:** 12-15 hours (manual + automated testing)
**Documentation Effort:** 8-10 hours (user guides, API docs)

**Total Effort:** 92-115 hours

**Assuming $100/hour rate:**
- Development: $7,200 - $9,000
- Testing: $1,200 - $1,500
- Documentation: $800 - $1,000

**Total Budget:** $9,200 - $11,500

**Additional Costs (External Services):**
- Twilio SMS: ~$0.0075 per SMS (estimated $50-200/month for 1000-5000 SMS)
- SendGrid Email: Free tier (100 emails/day), Pro tier $19.95/month (40K emails/day)
- Total External Services: ~$70-220/month

---

## Approval & Sign-off

**Prepared By:** Winston (Architect)
**Date:** 2025-11-10
**Status:** üìã Awaiting Product Owner Approval

**Approvals Required:**
- [ ] Product Owner - Business value and priorities
- [ ] Development Lead - Technical feasibility and timeline
- [ ] Security Lead - Security and privacy compliance
- [ ] QA Lead - Testing strategy and acceptance criteria
- [ ] Operations Lead - External service dependencies and costs

---

## Change Log

| Date | Version | Changes | Author |
|------|---------|---------|--------|
| 2025-11-10 | 1.0 | Initial Epic 7 proposal created | Winston (Architect) |

---

## Related Documentation

- **Epic 5:** Web Dashboard & Real-Time Monitoring (prerequisite)
- **Epic 6:** Advanced Analytics & Visualization (anomaly detection integration)
- **Architecture:** `docs/architecture/epic-5-architecture-review.md`
- **Configuration:** `config/config.yaml`

---

## Contact

For questions or feedback about Epic 7 proposal:
- **Architect:** Winston
- **Email:** (To be provided)
- **Slack:** #video-recognition-project
